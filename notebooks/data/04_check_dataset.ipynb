{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the manually constructed dataset of mining areas and ground truth masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import leafmap\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, mapping, box, shape\n",
    "import shapely\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "root = os.path.dirname(os.getcwd())\n",
    "# root = root + \"/workspaces/mine-segmentation\" # uncomment when running in Lightning Studios\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = root + \"/data/raw/mining_tiles_with_masks.gpkg\"\n",
    "post_dataset = root + \"/data/processed/mining_tiles_with_masks_and_bounding_boxes.gpkg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.list_layers(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = gpd.read_file(raw_dataset, layer=\"tiles\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution in minetype1 column\n",
    "data[\"minetype1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution in source_dataset column\n",
    "data.source_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out only tiles with valid surface mines\n",
    "data = data[data[\"minetype1\"].isin([\"Surface\", \"Placer\"]) & data[\"source_dataset\"].isin([\"maus\", \"tang\", \"both\"])]\n",
    "print(data.shape)\n",
    "data.source_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many tiles are overlapping with other tiles\n",
    "data[\"overlaps\"] = data[\"geometry\"].apply(lambda x: data[\"geometry\"].apply(lambda y: x.overlaps(y)).sum())\n",
    "data[\"overlaps\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overlap percentage of each tile\n",
    "data[\"overlap_percentage\"] = data[\"geometry\"].apply(lambda x: data[\"geometry\"].apply(lambda y: x.intersection(y).area/x.area).sum() - 1)\n",
    "data[\"overlap_percentage\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign validation label to the tiles with overlap percentage less than 0.1\n",
    "data[\"validation_eligible\"] = data[\"overlap_percentage\"].apply(lambda x: 1 if x < 0.1 else 0)\n",
    "data[\"validation_eligible\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Leaflet map\n",
    "m = leafmap.Map()\n",
    "\n",
    "style_eligible = {\n",
    "    \"stroke\": True,\n",
    "    \"color\": \"green\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 1,\n",
    "    \"fill\": True,\n",
    "    \"fillColor\": \"green\",\n",
    "}\n",
    "\n",
    "# change the color of the tiles with overlap percentage less than 0.1\n",
    "m.add_gdf(data[data[\"validation_eligible\"] == 1], layer_name=\"validation_eligible\", style=style_eligible)\n",
    "\n",
    "style_not_eligible = {\n",
    "    \"stroke\": True,\n",
    "    \"color\": \"red\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 1,\n",
    "    \"fill\": True,\n",
    "    \"fillColor\": \"red\",\n",
    "}\n",
    "\n",
    "# change the color of the tiles with overlap percentage more than 0.1\n",
    "m.add_gdf(data[data[\"validation_eligible\"] == 0], layer_name=\"validation_not_eligible\", style=style_not_eligible)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Overlapping Tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Assuming `data` is a GeoDataFrame with a 'geometry' column containing Polygon geometries\n",
    "\n",
    "# Step 1: Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Step 2: Add nodes\n",
    "for idx, geom in data.iterrows():\n",
    "    G.add_node(idx, geometry=geom.geometry)\n",
    "\n",
    "# Step 3: Add edges for overlapping or touching geometries\n",
    "for i, geom1 in data.iterrows():\n",
    "    for j, geom2 in data.iterrows():\n",
    "        if i != j and (geom1.geometry.overlaps(geom2.geometry) or geom1.geometry.touches(geom2.geometry)):\n",
    "            G.add_edge(i, j)\n",
    "\n",
    "# Step 4: Find connected components\n",
    "connected_components = list(nx.connected_components(G))\n",
    "\n",
    "# Step 5: Assign group IDs\n",
    "group_id = 0\n",
    "data['overlap_group'] = -1\n",
    "for component in connected_components:\n",
    "    for idx in component:\n",
    "        data.at[idx, 'overlap_group'] = group_id\n",
    "    group_id += 1\n",
    "\n",
    "print(f\"Number of connected components: {len(connected_components)}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Leaflet map\n",
    "m = leafmap.Map()\n",
    "m.add_gdf(data)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot groups by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import leafmap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Step 2: Define styles\n",
    "def get_group_color(group_id, num_groups):\n",
    "    cmap = plt.get_cmap('tab20')  # Use a colormap with enough distinct colors\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=num_groups - 1)\n",
    "    return mcolors.to_hex(cmap(norm(group_id)))\n",
    "\n",
    "# Get the number of unique groups\n",
    "num_groups = data['overlap_group'].nunique()\n",
    "\n",
    "# Step 3: Add tiles to the map\n",
    "m = leafmap.Map()\n",
    "\n",
    "for group_id in data['overlap_group'].unique():\n",
    "    group_data = data[data['overlap_group'] == group_id]\n",
    "    color = get_group_color(group_id, num_groups)\n",
    "    style = {\n",
    "        \"stroke\": True,\n",
    "        \"color\": color,\n",
    "        \"weight\": 2,\n",
    "        \"opacity\": 1,\n",
    "        \"fill\": True,\n",
    "        \"fillColor\": color,\n",
    "        \"fillOpacity\": 0.5,\n",
    "    }\n",
    "    m.add_gdf(group_data, layer_name=f\"group_{group_id}\", style=style)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global distribution of tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Markers on leafmap\n",
    "def plot_tiles_on_basemap(gdf):\n",
    "    import folium\n",
    "\n",
    "    m = folium.Map()\n",
    "\n",
    "    # Iterate over the tiles and add markers to the map\n",
    "    for _, row in gdf.iterrows():\n",
    "        lat = row.geometry.centroid.y\n",
    "        lon = row.geometry.centroid.x\n",
    "        folium.Marker([lat, lon]).add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    return m\n",
    "\n",
    "plot_tiles_on_basemap(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list layernames \n",
    "gpd.list_layers(post_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed dataset\n",
    "tiles = gpd.read_file(post_dataset, layer=\"tiles\")\n",
    "maus_poly = gpd.read_file(post_dataset, layer=\"maus_polygons\")\n",
    "tang_poly = gpd.read_file(post_dataset, layer=\"tang_polygons\")\n",
    "preferred_poly = gpd.read_file(post_dataset, layer=\"preferred_polygons\")\n",
    "maus_bbox = gpd.read_file(post_dataset, layer=\"maus_bboxes\")\n",
    "tang_bbox = gpd.read_file(post_dataset, layer=\"tang_bboxes\")\n",
    "preferred_bbox = gpd.read_file(post_dataset, layer=\"preferred_bboxes\")\n",
    "tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct one coherent dataset with the preferred mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW = 6\n",
    "\n",
    "m = leafmap.Map(center = (tiles.iloc[ROW:ROW+1].geometry.centroid.y.values[0], tiles.iloc[ROW:ROW+1].geometry.centroid.x.values[0]), zoom = 12)\n",
    "# add satellite\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "style_tile = {\n",
    "    \"color\": \"orange\",\n",
    "    \"fillColor\": \"orange\",\n",
    "    \"fillOpacity\": 0.0,\n",
    "}\n",
    "\n",
    "style_bbox = {\n",
    "    \"color\": \"green\",\n",
    "    \"fillColor\": \"green\",\n",
    "    \"fillOpacity\": 0.0,\n",
    "}\n",
    "\n",
    "m.add_gdf(tiles.iloc[ROW:ROW+1], layer_name=\"tiles\", style=style_tile)\n",
    "m.add_gdf(preferred_poly.iloc[ROW:ROW+1], layer_name=\"masks\")\n",
    "m.add_gdf(preferred_bbox.iloc[ROW:ROW+1], layer_name=\"bboxes\", style=style_bbox)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERED DATASET\n",
    "This includes the train/test/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only tiles with split\n",
    "data = tiles[tiles[\"split\"].notnull()]\n",
    "print(data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide unique value counts for categorical columns\n",
    "categorical_columns = ['source_dataset', 'preferred_dataset', 'minetype1', 'minetype2', 'split']\n",
    "for col in categorical_columns:\n",
    "    print(f\"Unique values in {col}:\")\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Leaflet map\n",
    "m = leafmap.Map(height=\"800px\")\n",
    "\n",
    "# add satellite layer\n",
    "# m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "style_train = {\n",
    "    \"stroke\": True,\n",
    "    \"color\": \"green\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 1,\n",
    "    \"fill\": True,\n",
    "    \"fillColor\": \"green\",\n",
    "}\n",
    "\n",
    "style_val = {\n",
    "    \"stroke\": True,\n",
    "    \"color\": \"blue\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 1,\n",
    "    \"fill\": True,\n",
    "    \"fillColor\": \"blue\",\n",
    "}\n",
    "\n",
    "style_test = {\n",
    "    \"stroke\": True,\n",
    "    \"color\": \"red\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 1,\n",
    "    \"fill\": True,\n",
    "    \"fillColor\": \"red\",\n",
    "}\n",
    "\n",
    "# Add train tiles to the map\n",
    "m.add_gdf(data[data[\"split\"] == \"train\"], layer_name=\"train\", style=style_train)\n",
    "\n",
    "# Add val tiles to the map\n",
    "m.add_gdf(data[data[\"split\"] == \"val\"], layer_name=\"val\", style=style_val)\n",
    "\n",
    "# Add test tiles to the map\n",
    "m.add_gdf(data[data[\"split\"] == \"test\"], layer_name=\"test\", style=style_test)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Leaflet map\n",
    "m = leafmap.Map()\n",
    "\n",
    "# Add the centroids of each test tile as markers\n",
    "test_tiles = data[data[\"split\"] == \"test\"]\n",
    "for _, row in test_tiles.iterrows():\n",
    "    lat = row.geometry.centroid.y\n",
    "    lon = row.geometry.centroid.x\n",
    "    m.add_marker(location=[lat, lon])\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Train Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split for the combined dataset\n",
    "print(f\"The train/val/test split for the combined dataset is: {data['split'].value_counts(normalize=True)}\")\n",
    "\n",
    "# train test split for the maus dataset\n",
    "print(f\"The train/val/test split for the maus dataset is: {data[data['source_dataset'].isin(['maus', 'both'])]['split'].value_counts(normalize=True)}\")\n",
    "\n",
    "# train test split for the tang dataset\n",
    "print(f\"The train/val/test split for the tang dataset is: {data[data['source_dataset'].isin(['tang', 'both'])]['split'].value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the source dataset in the test split\n",
    "data[data[\"split\"] == \"test\"][\"source_dataset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"split\"] == \"test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
