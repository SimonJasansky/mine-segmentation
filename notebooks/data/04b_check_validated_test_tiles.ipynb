{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import leafmap as leafmap\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, mapping, box, shape\n",
    "import shapely\n",
    "from typing import List\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"..\")\n",
    "root = os.path.dirname(os.getcwd())\n",
    "# root = root + \"/workspaces/mine-segmentation\" # uncomment when running in Lightning Studios\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_annotations = root + \"/data/raw/mining_tiles_test_annotations.gpkg\"\n",
    "DATASET = root + \"/data/processed/mining_tiles_with_masks_and_bounding_boxes.gpkg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONE-TIME Step: Add validated polygons to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(test_dataset_annotations):\n",
    "    raise FileNotFoundError(f\"Dataset {test_dataset_annotations} does not exist\")\n",
    "\n",
    "existing_layers = gpd.list_layers(DATASET).name.to_list()\n",
    "print(existing_layers)\n",
    "\n",
    "if not \"test_polygons_validated\" in existing_layers:\n",
    "    test_polygons_validated = gpd.read_file(test_dataset_annotations, layer=\"polygons_annotated\")\n",
    "    test_polygons_validated.to_file(DATASET, layer=\"test_polygons_validated\", driver=\"GPKG\")\n",
    "    print(\"Layer test_polygons_validated created in DATASET\")\n",
    "else:\n",
    "    test_polygons_validated = gpd.read_file(DATASET, layer=\"test_polygons_validated\")\n",
    "    print(\"Layer test_polygons_validated already exists, read from DATASET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the validated polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original and validated polygons\n",
    "tiles = gpd.read_file(DATASET, layer=\"tiles\")\n",
    "test_tiles = tiles[tiles[\"split\"] == \"test\"]\n",
    "\n",
    "# load original and validated polygons\n",
    "test_polygons_original = gpd.read_file(DATASET, layer=\"preferred_polygons\")\n",
    "test_polygons_original = pd.merge(test_tiles[[\"tile_id\"]], test_polygons_original, on=\"tile_id\", how=\"left\")\n",
    "\n",
    "test_polygons_validated = gpd.read_file(DATASET, layer=\"test_polygons_validated\")\n",
    "test_polygons_validated = pd.merge(test_tiles[[\"tile_id\"]], test_polygons_validated, on=\"tile_id\", how=\"left\")\n",
    "\n",
    "# load original polygons for maus and tang\n",
    "maus_test_polygons_original = gpd.read_file(DATASET, layer=\"maus_polygons\")\n",
    "maus_test_polygons_original = pd.merge(test_tiles[test_tiles[\"preferred_dataset\"] == \"maus\"][[\"tile_id\"]], maus_test_polygons_original, on=\"tile_id\", how=\"left\")\n",
    "\n",
    "tang_test_polygons_original = gpd.read_file(DATASET, layer=\"tang_polygons\")\n",
    "tang_test_polygons_original = pd.merge(test_tiles[test_tiles[\"preferred_dataset\"] == \"tang\"][[\"tile_id\"]], tang_test_polygons_original, on=\"tile_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polygons_original.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polygons_validated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two dataframes into one\n",
    "test_polygons = pd.merge(test_polygons_original, test_polygons_validated, on=\"tile_id\", suffixes=(\"_original\", \"_validated\"))\n",
    "test_polygons.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the tile geometry to the dataframe\n",
    "test_polygons = pd.merge(test_polygons, test_tiles[[\"tile_id\", \"geometry\"]], on=\"tile_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the metrics for the original and validated polygons\n",
    "def calculate_metrics(row: pd.Series) -> pd.Series:\n",
    "    original = row.geometry_original\n",
    "    validated = row.geometry_validated\n",
    "    tile = row.geometry\n",
    "\n",
    "    true_positive_area = original.intersection(validated).area # both original and validated are present\n",
    "    false_negative_area = validated.difference(original).area # validated is present, but original is not, thus it is a false negative\n",
    "    false_positive_area = original.difference(validated).area # original is present, but validated is not, thus it is a false positive\n",
    "    true_negative_area = tile.area - original.union(validated).area # neither original nor validated are present\n",
    "\n",
    "    accuracy = (true_positive_area + true_negative_area) / tile.area\n",
    "    precision = true_positive_area / (true_positive_area + false_positive_area)\n",
    "    recall = true_positive_area / (true_positive_area + false_negative_area)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    iou = true_positive_area / original.union(validated).area\n",
    "    sensitivity = true_positive_area / original.area\n",
    "    specificity = true_negative_area / (true_negative_area + false_positive_area)\n",
    "\n",
    "\n",
    "    # accuracy = original.intersection(validated).area / max(original.area, validated.area)\n",
    "    # precision = original.intersection(validated).area / original.area\n",
    "    # recall = original.intersection(validated).area / validated.area\n",
    "    # f1 = 2 * original.intersection(validated).area / (original.area + validated.area)\n",
    "    # iou = original.intersection(validated).area / original.union(validated).area\n",
    "    # sensitivity = original.intersection(validated).area / original.area\n",
    "    # specificity = 1 - (original.difference(validated).area / original.area)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"tile_id\": row.tile_id,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"iou\": iou,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"true_positive_area\": true_positive_area,\n",
    "        \"false_negative_area\": false_negative_area,\n",
    "        \"false_positive_area\": false_positive_area,\n",
    "        \"true_negative_area\": true_negative_area\n",
    "    })\n",
    "\n",
    "test_polygons_metrics = test_polygons.progress_apply(calculate_metrics, axis=1)\n",
    "test_polygons_metrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the averages\n",
    "test_polygons_metrics[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for all the metrics\n",
    "test_polygons_metrics[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].hist(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_area = test_polygons_metrics[\"true_positive_area\"].mean()\n",
    "false_negative_area = test_polygons_metrics[\"false_negative_area\"].mean()\n",
    "false_positive_area = test_polygons_metrics[\"false_positive_area\"].mean()\n",
    "true_negative_area = test_polygons_metrics[\"true_negative_area\"].mean()\n",
    "sum_areas = true_positive_area + false_negative_area + false_positive_area + true_negative_area\n",
    "\n",
    "# calculate percentages\n",
    "true_positive_area = true_positive_area / sum_areas * 100\n",
    "false_negative_area = false_negative_area / sum_areas * 100\n",
    "false_positive_area = false_positive_area / sum_areas * 100\n",
    "true_negative_area = true_negative_area / sum_areas * 100\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "confusion_matrix_values = np.array([[true_positive_area, false_negative_area], [false_positive_area, true_negative_area]])\n",
    "class_names = ['Mining Area', 'No Mining Area']\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_values, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.xlabel('Original Polygon')\n",
    "plt.ylabel('Validated Polygon')\n",
    "\n",
    "# remove the bar \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the metrics with the polygons\n",
    "test_polygons = pd.merge(test_polygons, test_polygons_metrics, on=\"tile_id\")\n",
    "test_polygons.sort_values(\"iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polygons = test_polygons.sort_values(\"iou\", ascending=True).reset_index(drop=True)\n",
    "test_polygons.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "m = leafmap.Map(\n",
    "        center=[test_polygons.geometry_original[index].centroid.y, test_polygons.geometry_original[index].centroid.x], \n",
    "        zoom=12,\n",
    "        height=\"900px\"\n",
    "    )\n",
    "\n",
    "# add satellite\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "original_polygon = test_polygons.geometry_original[index]\n",
    "validated_polygon = test_polygons.geometry_validated[index]\n",
    "\n",
    "print(test_polygons.iou[index])\n",
    "print(test_polygons.tile_id[index])\n",
    "\n",
    "# add the original polygon\n",
    "m.add_geojson(mapping(original_polygon), layer_name=\"original\", style={\"color\": \"blue\", \"fillOpacity\": 0.5})\n",
    "\n",
    "# add the validated polygon\n",
    "m.add_geojson(mapping(validated_polygon), layer_name=\"validated\", style={\"color\": \"red\", \"fillOpacity\": 0.5})\n",
    "\n",
    "# add the tile\n",
    "m.add_geojson(mapping(test_polygons.geometry[index]), layer_name=\"tile\", style={\"color\": \"orange\", \"fillOpacity\": 0.0})\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics for Maus and Tang Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_polygons_maus = pd.merge(maus_test_polygons_original, test_polygons_validated, on=\"tile_id\", suffixes=(\"_original\", \"_validated\"))\n",
    "test_polygons_tang = pd.merge(tang_test_polygons_original, test_polygons_validated, on=\"tile_id\", suffixes=(\"_original\", \"_validated\"))\n",
    "\n",
    "# add the tile geometry to the dataframe\n",
    "test_polygons_maus = pd.merge(test_polygons_maus, test_tiles[[\"tile_id\", \"geometry\"]], on=\"tile_id\")\n",
    "test_polygons_tang = pd.merge(test_polygons_tang, test_tiles[[\"tile_id\", \"geometry\"]], on=\"tile_id\")\n",
    "\n",
    "test_polygons_maus_metrics = test_polygons_maus.progress_apply(calculate_metrics, axis=1)\n",
    "test_polygons_tang_metrics = test_polygons_tang.progress_apply(calculate_metrics, axis=1)\n",
    "\n",
    "test_polygons_maus = pd.merge(test_polygons_maus, test_polygons_maus_metrics, on=\"tile_id\")\n",
    "test_polygons_tang = pd.merge(test_polygons_tang, test_polygons_tang_metrics, on=\"tile_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the averages\n",
    "test_polygons_maus[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for all the metrics\n",
    "test_polygons_maus[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].hist(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the averages\n",
    "test_polygons_tang[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for all the metrics\n",
    "test_polygons_tang[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"iou\", \"sensitivity\", \"specificity\"]].hist(figsize=(20, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineseg-clay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
