{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set working directory to root \n",
    "import os\n",
    "os.chdir(\"../../\")\n",
    "root = os.getcwd()\n",
    "root = root + \"/workspaces/mine-segmentation\" # for lightning studios\n",
    "print(f\"Root directory: {root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# import leafmap\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from einops import rearrange\n",
    "# from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import jaccard_score, f1_score, accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "# from shapely.wkt import loads\n",
    "# import datetime\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from src.models.datamodule import MineDataModule\n",
    "from src.models.cnn.model import MineSegmentorCNN\n",
    "from src.models.clay.segment.model import MineSegmentor\n",
    "\n",
    "from src.data.get_satellite_images import ReadSTAC\n",
    "\n",
    "from src.visualization.visualization_funcs import plot_pred_vs_true_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512 model\n",
    "MINESEG_CHECKPOINT_PATH = (\"models/cnn/mineseg-cnn_epoch-21_val-iou-0.5826.ckpt\")\n",
    "CHIP_SIZE = 512\n",
    "TESTSET_BATCH_SIZE = 16 # 32 for L4, 16 for PC GPU\n",
    "TRAIN_CHIP_DIR = \"data/processed/chips/npy/512/train/chips/\"\n",
    "TRAIN_LABEL_DIR = \"data/processed/chips/npy/512/train/labels/\"\n",
    "VAL_CHIP_DIR = \"data/processed/chips/npy/512/val/chips/\"\n",
    "VAL_LABEL_DIR = \"data/processed/chips/npy/512/val/labels/\"\n",
    "TEST_CHIP_DIR = \"data/processed/chips/npy/512/test/chips/\"\n",
    "TEST_LABEL_DIR = \"data/processed/chips/npy/512/test/labels/\"\n",
    "TEST_CHIP_VALIDATED_DIR = \"data/processed/chips/npy/512/validated/test/chips/\"\n",
    "TEST_LABEL_VALIDATED_DIR = \"data/processed/chips/npy/512/validated/test/labels/\"\n",
    "VALIDATION_CHIP_DIR = \"data/processed/chips/npy/512/validation/chips/\"\n",
    "METADATA_PATH = \"configs/cnn/cnn_segment_metadata.yaml\"\n",
    "CLAY = False\n",
    "\n",
    "\n",
    "# general setup\n",
    "DATASET = \"data/processed/mining_tiles_with_masks_and_bounding_boxes.gpkg\"\n",
    "BATCH_SIZE = 1\n",
    "if torch.cuda.is_available():\n",
    "    NUM_WORKERS = 16\n",
    "else:\n",
    "    NUM_WORKERS = 4\n",
    "PLATFORM = \"sentinel-2-l2a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLAY:\n",
    "    CLAY_CHECKPOINT_PATH = root + \"/\" + CLAY_CHECKPOINT_PATH\n",
    "\n",
    "MINESEG_CHECKPOINT_PATH = root + \"/\" + MINESEG_CHECKPOINT_PATH\n",
    "METADATA_PATH = root + \"/\" + METADATA_PATH\n",
    "TRAIN_CHIP_DIR = root +  \"/\" + TRAIN_CHIP_DIR\n",
    "TRAIN_LABEL_DIR = root + \"/\" + TRAIN_LABEL_DIR\n",
    "VAL_CHIP_DIR = root + \"/\" + VAL_CHIP_DIR\n",
    "VAL_LABEL_DIR = root + \"/\" + VAL_LABEL_DIR\n",
    "TEST_CHIP_DIR = root + \"/\" + TEST_CHIP_DIR\n",
    "TEST_LABEL_DIR = root + \"/\" + TEST_LABEL_DIR\n",
    "TEST_CHIP_VALIDATED_DIR = root + \"/\" + TEST_CHIP_VALIDATED_DIR\n",
    "TEST_LABEL_VALIDATED_DIR = root + \"/\" + TEST_LABEL_VALIDATED_DIR\n",
    "DATASET = root + \"/\" + DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model mineseg-cnn_epoch-21_val-iou-0.5826.ckpt\n",
      "Using chip size 512\n",
      "Using test chip dir /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation/data/processed/chips/npy/512/test/chips/\n",
      "Using test label dir /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation/data/processed/chips/npy/512/test/labels/\n",
      "Using validated chip dir /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation/data/processed/chips/npy/512/validated/test/chips/\n",
      "Using validated label dir /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation/data/processed/chips/npy/512/validated/test/labels/\n",
      "Using test batch size 16\n",
      "Using dataset /teamspace/studios/this_studio/workspaces/mine-segmentation/workspaces/mine-segmentation/data/processed/mining_tiles_with_masks_and_bounding_boxes.gpkg\n"
     ]
    }
   ],
   "source": [
    "model_name = MINESEG_CHECKPOINT_PATH.split(\"/\")[-1]\n",
    "print(f\"Using model {model_name}\")\n",
    "print(f\"Using chip size {CHIP_SIZE}\")\n",
    "print(f\"Using test chip dir {TEST_CHIP_DIR}\")\n",
    "print(f\"Using test label dir {TEST_LABEL_DIR}\")\n",
    "print(f\"Using validated chip dir {TEST_CHIP_VALIDATED_DIR}\")\n",
    "print(f\"Using validated label dir {TEST_LABEL_VALIDATED_DIR}\")\n",
    "print(f\"Using test batch size {TESTSET_BATCH_SIZE}\")\n",
    "print(f\"Using dataset {DATASET}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLAY:\n",
    "    def get_model(mineseg_checkpoint_path, clay_checkpoint_path, metadata_path):\n",
    "        model = MineSegmentor.load_from_checkpoint(\n",
    "            checkpoint_path=mineseg_checkpoint_path,\n",
    "            metadata_path=metadata_path,\n",
    "            ckpt_path=clay_checkpoint_path,\n",
    "        )\n",
    "        model.eval()\n",
    "        return model\n",
    "else: \n",
    "    def get_model(checkpoint_path: str) -> MineSegmentorCNN:\n",
    "        # check if gpu is available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        map_location=torch.device(device)\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
    "        model_config = checkpoint[\"hyper_parameters\"]\n",
    "        model = MineSegmentorCNN.load_from_checkpoint(checkpoint_path, **model_config)\n",
    "        model.eval()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading full S2 Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stack...\n",
      "Returning stack from single S2 image with ID: S2B_MSIL2A_20250120T153629_R068_T17MQN_20250120T205019\n"
     ]
    }
   ],
   "source": [
    "# search on planetary computer for tile id that you like\n",
    "tile_id = \"S2B_MSIL2A_20250120T153629_R068_T17MQN_20250120T205019\"\n",
    "\n",
    "# Download the image \n",
    "api_url=\"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "bands = ['B04', 'B03', 'B02', 'B08']\n",
    "\n",
    "stac_reader = ReadSTAC(api_url=api_url, collection = \"sentinel-2-l2a\")\n",
    "\n",
    "item = stac_reader.get_item_by_name(tile_id)\n",
    "\n",
    "# read as stack\n",
    "stack = stac_reader.get_stack(\n",
    "    items=item, \n",
    "    bands=bands,\n",
    "    crop_to_bounds=False, \n",
    "    squeeze_time_dim=True,\n",
    "    # custom_point_and_buffer=[lon, lat, 10240],\n",
    "    chunk_size=512,\n",
    "    )\n",
    "\n",
    "# save geotiff\n",
    "file_path = f\"data/interim/{tile_id}.tif\"\n",
    "stac_reader.save_stack_as_geotiff(stack, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_chips import read_and_chip\n",
    "\n",
    "output_dir = \"data/processed/chips/npy/512/validation/chips/\"\n",
    "\n",
    "read_and_chip(\n",
    "    file_path=file_path, \n",
    "    chip_size=512, \n",
    "    output_dir=output_dir, \n",
    "    chip_format=\"npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(\n",
    "    train_chip_dir,\n",
    "    train_label_dir,\n",
    "    val_chip_dir,\n",
    "    val_label_dir,\n",
    "    test_chip_dir,\n",
    "    test_label_dir,\n",
    "    metadata_path,\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    platform,\n",
    "    data_augmentation,\n",
    "    index=None\n",
    "):\n",
    "    dm = MineDataModule(\n",
    "        train_chip_dir=train_chip_dir,\n",
    "        train_label_dir=train_label_dir,\n",
    "        val_chip_dir=val_chip_dir,\n",
    "        val_label_dir=val_label_dir,\n",
    "        test_chip_dir=test_chip_dir,\n",
    "        test_label_dir=test_label_dir,\n",
    "        metadata_path=metadata_path,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        platform=platform,\n",
    "        data_augmentation=data_augmentation,\n",
    "    )\n",
    "    \n",
    "    dm.setup(stage=\"test\")\n",
    "    \n",
    "    if index is not None:\n",
    "        test_dl = iter(dm.test_dataloader())\n",
    "        for i in range(index + 1):\n",
    "            batch = next(test_dl)\n",
    "        metadata = dm.metadata\n",
    "        return batch, metadata\n",
    "    else:\n",
    "        test_dl = dm.test_dataloader()\n",
    "        batch = next(iter(test_dl))\n",
    "        metadata = dm.metadata\n",
    "        return batch, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(model, batch, is_clay=False):\n",
    "    with torch.no_grad():\n",
    "        if is_clay:\n",
    "            image=batch\n",
    "        else:\n",
    "            image = batch[\"pixels\"]\n",
    "        outputs = model(image)\n",
    "    outputs = F.interpolate(\n",
    "        outputs, size=(CHIP_SIZE, CHIP_SIZE), mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
